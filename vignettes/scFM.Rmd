---
title: "scFM: Bayesian segmented Gaussian copula factor model for single-cell sequencing data"
author: "Junsouk Choi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{scFM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = FALSE
)
```


# Introduction

The 'scFM' package implements the Segmented Gaussian Copula Factor Model (scFM), a Bayesian latent factor model designed for single-cell RNA sequencing (scRNA-seq) data, as introduced by Choi et al. (2024). As described in the paper, "The proposed segmented Gaussian copula factor model (scFM) handles both zero-inflated and skewed counts in scRNA-seq data by introducing a segmentation of the empirical marginal distribution" (Section 1, Choi et al., 2024).

# Data Preparation

This vignette uses the scFM package, which provides the core functionality for the Segmented Gaussian Copula Factor Model and includes the built-in dataset used in this analysis. The paper describes the dataset: "We use the GM12878 cell line (LCL) dataset, which consists of 5,135 cells and 100 genes after preprocessing" (Section 5, Choi et al., 2024).

```{r load-data, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# Load the scFM package, which provides the core functionality and built-in dataset
library(scFM)
set.seed(7)
# Load the built-in LCL dataset
data(LCL)
x = LCL
# Check dimensions of the dataset
dim(x)
```

# Model Initialization and Prior Setup

```{r load-packages, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# load necessary packages
library(tmvnsim)
library(tmvtnorm)
library(GIGrvg)
library(actuar)
library(ggplot2)
library(SingleR)
library(celldex)
library(tibble)
```

## Hyperparameter Settings

```{r set-priors, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# set hyperparameters
priors = list()
priors$Sigma = c(0.1, 0.1)
priors$Phi   = 0.5
```


## Empirical Marginal Transformation

We transform the marginal distributions of observed counts to approximate standard normals using empirical CDFs

```{r init-Z-delta, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# initialize parameters Z, delta
starting = list()
n = nrow(x)
p = ncol(x)
k = 8
ecdf.scale = n / (n + 1)
eFx   = apply(x, 2, ecdf)
eFx   = lapply(eFx, function(x){  function(y) ecdf.scale * x(y)  })
eFxx  = Map(function(f, x) do.call(f, list(x)), eFx, plyr::alply(x, 2))
starting$Z     = matrix(unlist(lapply(eFxx, function(pr) qnorm(pr))), n, p)
starting$delta = matrix(0, p, 2)
starting$delta[ , 1] = qnorm(colMeans(x == 0))
starting$delta[ , 2] = qnorm(colMeans(x <= 1))
```


## Initial Factor Estimates via Factor Analysis

We initialize the loadings and scores using standard factor analysis on the latent Z.

```{r init-Lambda-U, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# initialize Lambda and U from factor analysis
out0 = factanal(starting$Z, factors = k, scores = "regression")
starting$Lambda = as.matrix(out0$loadings)
starting$U = out0$scores
```


## Sampling Prior Hyperparameters

We sample the column-wise global parameter $\phi$, local parameter $\psi$, and overall shrinkage $\tau$ using their full conditionals.

```{r sampling-hyperparamters, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# Sampling Hyperparameters for Initialization
Sigma = diag(1, p)
Phi = rep(1 / k, k)
tau = 1
Psi = matrix(rexp(p * k, rate = 0.5), p, k)

for (iter in 1 : 1000) {
   Sigma[diag(rep(TRUE, p))] = 1 / rgamma(p, shape = priors$Sigma[1] + rep(n / 2, p), 
                                          rate = priors$Sigma[2] + 0.5 * colSums((starting$Z - tcrossprod(starting$U, starting$Lambda))^2))
   
   H = rep(NA, k)
   for (l in 1 : k) {
      H[l] = rgig(1, lambda = priors$Phi - p, chi = 2 * sum(abs(starting$Lambda[ , l])), psi = 1)
   }
   Phi = H / sum(H)
   tau = rgig(1, lambda = k * (priors$Phi - p), chi = 2 * sum(t(abs(starting$Lambda)) / Phi), psi = 1)
   Psi_tilde = rinvgauss(p * k, mean = c(t(Phi * t(tau / abs(starting$Lambda)))))
   Psi = matrix(1 / Psi_tilde, p, k)
}

starting$Sigma = Sigma
starting$Phi   = Phi
starting$tau   = tau
starting$Psi   = Psi
```

# Posterior Inference

## Gibbs Sampling

We implement a blocked Gibbs sampler for the scFM model to obtain posterior draws from the parameters

```{r scFM, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
#nmcmc   = 100
#nburnin = 50
#p.time = proc.time()
#out    = gibbs_scFM(x, k, starting, priors, nmcmc = nmcmc, nburnin = nburnin)
#proc.time() - p.time

load("/Users/admin/Desktop/scFM_scRNAseq.RData")  # loads 'x', 'anno', 'out'
```


We compute posterior means of the factor loadings and scores by averaging over MCMC samples.

```{r posterior-means, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# Compute posterior means
loading_est = apply(out$Lambda, c(1, 2), mean) 
score_est = apply(out$U, c(1, 2), mean) 
```


## Latent Factor Selection

To identify significant latent factors, we perform k-means clustering on the columns of Lambda.

```{r identify-significant-factors, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# Identify significant factors using k-means clustering
sig_facto = matrix(0, dim(out$Lambda)[2], dim(out$Lambda)[3])
for (i in 1 : dim(out$Lambda)[3])
{
   kmeans_lambda = kmeans(t(out$Lambda[ , , i]), centers = 2, nstart = 10)
   sig_facto[which(kmeans_lambda$cluster == which.max(rowSums(kmeans_lambda$centers^2))), i] = 1
}
table(colSums(sig_facto))
rowMeans(sig_facto)   # only the first two factors are significant

score_est_all = score_est
score_est = score_est[ , 1 : 2]
```

# Downstream analysis

We use the estimated factor scores to cluster cells and visualize latent structure.

## Clustering and Visualization

```{r scree-plot, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# Scree plot to determine number of clusters
n_clusters = 10
wss = numeric(n_clusters)
for (i in 1 : n_clusters)
{
   # fit the model: km.out
   km.out = kmeans(score_est, centers = i, nstart = 100, iter.max = 10000)
   # save the within cluster sum of squares
   wss[i] = km.out$tot.withinss
}

# produce a scree plot to determine the number of the underlying cell types
wss_df = tibble(clusters = 1 : n_clusters, wss = wss)
scree_plot = ggplot(wss_df, aes(x = clusters, y = wss, group = 1)) + 
   geom_point(size = 4) + 
   geom_line() +
   scale_x_continuous(breaks = c(2, 4, 6, 8, 10)) +
   xlab('Number of clusters')
scree_plot
```

We visualize the clustering results on the first two significant factors identified by our shrinkage prior.

```{r clustering, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# Apply k-means clustering with chosen k = 3
out_cell_types = kmeans(score_est, centers = 3, nstart = 100, iter.max = 10000)
df = data.frame(facto1 = score_est[ , 1], facto2 = score_est[ , 2], Cluster = factor(out_cell_types$cluster))
plot_cell_types = ggplot(df[-4148, ], aes(facto1, facto2, color = Cluster)) + geom_point(alpha = 0.3) + labs(x = "Factor 1", y = "Factor 2")
plot_cell_types
```

## Top Genes by Factors

```{r top-10, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# Plot top 10 genes by loadings on each factor
rownames(loading_est) = colnames(x)

order1 = order(abs(loading_est[ , 1]), decreasing = TRUE)
df = data.frame(gene = factor(colnames(x), levels = colnames(x)[order1]), value = abs(loading_est[ , 1]))
loading1 = ggplot(df, aes(x = gene, y = value)) + geom_bar(stat = "identity") + scale_x_discrete(guide = guide_axis(n.dodge = 5)) + labs(x = "Genes", y = "Absolute loadings on factor 1")
loading1

order2 = order(abs(loading_est[ , 2]), decreasing = TRUE)
df = data.frame(gene = factor(colnames(x), levels = colnames(x)[order2]), value = abs(loading_est[ , 2]))
loading2 = ggplot(df, aes(x = gene, y = value)) + geom_bar(stat = "identity") + scale_x_discrete(guide = guide_axis(n.dodge = 5)) + labs(x = "Genes", y = "Absolute loadings on factor 2")
loading2

# top 10 significant factor loadings
sort(loading_est[rank(abs(loading_est[ , 1])) > 90, 1], decreasing = TRUE)
sort(loading_est[rank(abs(loading_est[ , 2])) > 90, 2], decreasing = TRUE)

round(colMeans(x[ , rank(abs(loading_est[ , 1])) > 90]), digits = 3)
round(colMeans(x[ , rank(abs(loading_est[ , 2])) > 90]), digits = 3)

# average expression of genes corresponding to significant loadings across different cell subtypes
round(colMeans(x[out_cell_types$cluster == 1, rank(abs(loading_est[ , 1])) > 90]), digits = 3)
round(colMeans(x[out_cell_types$cluster == 1, rank(abs(loading_est[ , 2])) > 90]), digits = 3)
round(colMeans(x[out_cell_types$cluster == 2, rank(abs(loading_est[ , 1])) > 90]), digits = 3)
round(colMeans(x[out_cell_types$cluster == 2, rank(abs(loading_est[ , 2])) > 90]), digits = 3)
round(colMeans(x[out_cell_types$cluster == 3, rank(abs(loading_est[ , 1])) > 90]), digits = 3)
round(colMeans(x[out_cell_types$cluster == 3, rank(abs(loading_est[ , 2])) > 90]), digits = 3)

```

## Cluster Annotation

```{r annotate, message = FALSE, eval = TRUE, echo = TRUE, cache = TRUE}
# Annotate clusters using SingleR
hpca.se = HumanPrimaryCellAtlasData()
hpca.se
annotate_clusters = SingleR(test = t(x), ref = hpca.se, clusters = out_cell_types$cluster, labels = hpca.se$label.main)
annotate_clusters
```
